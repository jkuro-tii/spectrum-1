diff -ruN linux-5.18.orig/drivers/char/mem.c linux-5.18/drivers/char/mem.c
--- linux-5.18.orig/drivers/char/mem.c	2022-05-22 23:52:31.000000000 +0400
+++ linux-5.18/drivers/char/mem.c	2022-12-08 13:27:22.921241484 +0400
@@ -119,7 +119,7 @@
 
 	if (p != *ppos)
 		return 0;
-
+#if 0
 	if (!valid_phys_addr_range(p, count))
 		return -EFAULT;
 	read = 0;
@@ -137,6 +137,7 @@
 		}
 	}
 #endif
+#endif
 
 	bounce = kmalloc(PAGE_SIZE, GFP_KERNEL);
 	if (!bounce)
diff -ruN linux-5.18.orig/drivers/nvdimm/core.c linux-5.18/drivers/nvdimm/core.c
--- linux-5.18.orig/drivers/nvdimm/core.c	2022-05-22 23:52:31.000000000 +0400
+++ linux-5.18/drivers/nvdimm/core.c	2022-12-06 12:06:33.590150505 +0400
@@ -17,6 +17,8 @@
 #include "nd-core.h"
 #include "nd.h"
 
+#define HERE printk("At %s: %s:%s", __FUNCTION__, __FILE__, __LINE__);
+
 LIST_HEAD(nvdimm_bus_list);
 DEFINE_MUTEX(nvdimm_bus_list_mutex);
 
@@ -69,6 +71,7 @@
 	struct nvdimm_bus *nvdimm_bus = walk_to_nvdimm_bus(dev);
 	struct nvdimm_map *nvdimm_map;
 
+	HERE;
 	list_for_each_entry(nvdimm_map, &nvdimm_bus->mapping_list, list)
 		if (nvdimm_map->offset == offset)
 			return nvdimm_map;
@@ -81,6 +84,7 @@
 	struct nvdimm_bus *nvdimm_bus = walk_to_nvdimm_bus(dev);
 	struct nvdimm_map *nvdimm_map;
 
+	HERE;
 	nvdimm_map = kzalloc(sizeof(*nvdimm_map), GFP_KERNEL);
 	if (!nvdimm_map)
 		return NULL;
@@ -99,10 +103,15 @@
 	}
 
 	if (flags)
+	{
 		nvdimm_map->mem = memremap(offset, size, flags);
+		printk("nvdimm_map->mem=%p", nvdimm_map->mem);
+	}
 	else
+	{
 		nvdimm_map->iomem = ioremap(offset, size);
-
+		printk("nvdimm_map->iomem=%p", nvdimm_map->iomem);
+	}
 	if (!nvdimm_map->mem)
 		goto err_map;
 
@@ -124,6 +133,7 @@
 	struct nvdimm_bus *nvdimm_bus;
 	struct nvdimm_map *nvdimm_map;
 
+	HERE;
 	nvdimm_map = container_of(kref, struct nvdimm_map, kref);
 	nvdimm_bus = nvdimm_map->nvdimm_bus;
 
@@ -142,6 +152,7 @@
 	struct nvdimm_map *nvdimm_map = data;
 	struct nvdimm_bus *nvdimm_bus = nvdimm_map->nvdimm_bus;
 
+	HERE;
 	nvdimm_bus_lock(&nvdimm_bus->dev);
 	kref_put(&nvdimm_map->kref, nvdimm_map_release);
 	nvdimm_bus_unlock(&nvdimm_bus->dev);
@@ -159,6 +170,7 @@
 {
 	struct nvdimm_map *nvdimm_map;
 
+	HERE;
 	nvdimm_bus_lock(dev);
 	nvdimm_map = find_nvdimm_map(dev, offset);
 	if (!nvdimm_map)
@@ -316,6 +328,7 @@
 
 static int flush_namespaces(struct device *dev, void *data)
 {
+	HERE;
 	nd_device_lock(dev);
 	nd_device_unlock(dev);
 	return 0;
@@ -323,6 +336,7 @@
 
 static int flush_regions_dimms(struct device *dev, void *data)
 {
+	HERE;
 	nd_device_lock(dev);
 	nd_device_unlock(dev);
 	device_for_each_child(dev, NULL, flush_namespaces);
@@ -336,6 +350,7 @@
 	struct nvdimm_bus_descriptor *nd_desc = nvdimm_bus->nd_desc;
 	int rc;
 
+	HERE;
 	if (nd_desc->flush_probe) {
 		rc = nd_desc->flush_probe(nd_desc);
 		if (rc)
@@ -365,6 +380,7 @@
 	struct nvdimm_bus_descriptor *nd_desc = nvdimm_bus->nd_desc;
 	enum nvdimm_fwa_capability cap;
 
+	HERE;
 	if (!nd_desc->fw_ops)
 		return -EOPNOTSUPP;
 
diff -ruN linux-5.18.orig/drivers/nvdimm/Makefile linux-5.18/drivers/nvdimm/Makefile
--- linux-5.18.orig/drivers/nvdimm/Makefile	2022-09-28 15:30:31.693035247 +0400
+++ linux-5.18/drivers/nvdimm/Makefile	2022-11-03 15:02:59.581279300 +0400
@@ -31,3 +31,5 @@
 TOOLS := ../../tools
 TEST_SRC := $(TOOLS)/testing/nvdimm/test
 obj-$(CONFIG_NVDIMM_TEST_BUILD) += $(TEST_SRC)/iomap.o
+cflags-y := -DDEBUG
+ccflags-y := -DDEBUG
diff -ruN linux-5.18.orig/drivers/nvdimm/namespace_devs.c linux-5.18/drivers/nvdimm/namespace_devs.c
--- linux-5.18.orig/drivers/nvdimm/namespace_devs.c	2022-05-22 23:52:31.000000000 +0400
+++ linux-5.18/drivers/nvdimm/namespace_devs.c	2022-12-09 09:48:37.858879525 +0400
@@ -1824,7 +1824,8 @@
 		kfree(nspm);
 		return NULL;
 	}
-	dev_set_name(dev, "namespace%d.%d", nd_region->id, nspm->id);
+	printk("n1amespace");
+	dev_set_name(dev, "n1amespace%d.%d", nd_region->id, nspm->id);
 	nd_namespace_pmem_set_resource(nd_region, nspm, 0);
 
 	return dev;
@@ -2199,7 +2200,8 @@
 
 		if (id < 0)
 			break;
-		dev_set_name(dev, "namespace%d.%d", nd_region->id, id);
+		printk("n2amespace");
+		dev_set_name(dev, "n2amespace%d.%d", nd_region->id, id);
 		nd_device_register(dev);
 	}
 	if (i)
diff -ruN linux-5.18.orig/drivers/nvdimm/nd_virtio.c linux-5.18/drivers/nvdimm/nd_virtio.c
--- linux-5.18.orig/drivers/nvdimm/nd_virtio.c	2022-05-22 23:52:31.000000000 +0400
+++ linux-5.18/drivers/nvdimm/nd_virtio.c	2022-11-03 14:59:28.622381761 +0400
@@ -100,6 +100,7 @@
 /* The asynchronous flush callback function */
 int async_pmem_flush(struct nd_region *nd_region, struct bio *bio)
 {
+	// printk("async_pmem_flush called!");
 	/*
 	 * Create child bio for asynchronous flush and chain with
 	 * parent bio. Otherwise directly call nd_region flush.
@@ -107,7 +108,7 @@
 	if (bio && bio->bi_iter.bi_sector != -1) {
 		struct bio *child = bio_alloc(bio->bi_bdev, 0, REQ_PREFLUSH,
 					      GFP_ATOMIC);
-
+		//printk("async_pmem_flush: executing bio...");
 		if (!child)
 			return -ENOMEM;
 		bio_clone_blkg_association(child, bio);
@@ -116,7 +117,9 @@
 		submit_bio(child);
 		return 0;
 	}
-	if (virtio_pmem_flush(nd_region))
+	int res = virtio_pmem_flush(nd_region);
+	// printk("async_pmem_flush: virtio_pmem_flush return: %d", res);
+	if (res)
 		return -EIO;
 
 	return 0;
diff -ruN linux-5.18.orig/drivers/nvdimm/pmem.c linux-5.18/drivers/nvdimm/pmem.c
--- linux-5.18.orig/drivers/nvdimm/pmem.c	2022-05-22 23:52:31.000000000 +0400
+++ linux-5.18/drivers/nvdimm/pmem.c	2022-12-13 16:13:57.601143258 +0400
@@ -31,6 +31,8 @@
 #include "pfn.h"
 #include "nd.h"
 
+// #define DBG
+
 static struct device *to_dev(struct pmem_device *pmem)
 {
 	/*
@@ -104,6 +106,9 @@
 	unsigned int chunk;
 	void *mem;
 
+#ifdef DBG
+	printk("write_pmem\n");
+#endif
 	while (len) {
 		mem = kmap_atomic(page);
 		chunk = min_t(unsigned int, len, PAGE_SIZE - off);
@@ -123,6 +128,7 @@
 	unsigned long rem;
 	void *mem;
 
+	// printk("read_pmem\n");
 	while (len) {
 		mem = kmap_atomic(page);
 		chunk = min_t(unsigned int, len, PAGE_SIZE - off);
@@ -163,6 +169,9 @@
 	phys_addr_t pmem_off = sector * 512 + pmem->data_offset;
 	void *pmem_addr = pmem->virt_addr + pmem_off;
 
+	#ifdef DBG
+	printk("pmem_do_write\n");
+	#endif
 	if (unlikely(is_bad_pmem(&pmem->bb, sector, len)))
 		bad_pmem = true;
 
@@ -201,9 +210,22 @@
 	struct pmem_device *pmem = bio->bi_bdev->bd_disk->private_data;
 	struct nd_region *nd_region = to_region(pmem);
 
+	#ifdef DBG
+	printk("pmem_submit_bio\n");
+	#endif
 	if (bio->bi_opf & REQ_PREFLUSH)
+	{
+		#ifdef DBG
+		printk("pmem_submit_bio: flush\n");
+		#endif
 		ret = nvdimm_flush(nd_region, bio);
-
+	}
+	else
+	{
+		#ifdef DBG
+		printk("pmem_submit_bio: no flush!\n");
+		#endif
+	}
 	do_acct = blk_queue_io_stat(bio->bi_bdev->bd_disk->queue);
 	if (do_acct)
 		start = bio_start_io_acct(bio);
@@ -237,6 +259,7 @@
 	struct pmem_device *pmem = bdev->bd_disk->private_data;
 	blk_status_t rc;
 
+	// printk("pmem_rw_page\n");
 	if (op_is_write(op))
 		rc = pmem_do_write(pmem, page, 0, sector, thp_size(page));
 	else
@@ -321,6 +344,9 @@
 	bool write_cache;
 	int rc;
 
+	#ifdef DBG
+	printk("write_cache_store\n");
+	#endif
 	rc = strtobool(buf, &write_cache);
 	if (rc)
 		return rc;
@@ -407,10 +433,19 @@
 	pmem->size = resource_size(res);
 	fua = nvdimm_has_flush(nd_region);
 	if (!IS_ENABLED(CONFIG_ARCH_HAS_UACCESS_FLUSHCACHE) || fua < 0) {
-		dev_warn(dev, "unable to guarantee persistence of writes\n");
+		if (IS_ENABLED(CONFIG_ARCH_HAS_PMEM_API))
+		{
+			dev_warn(dev, "CONFIG_ARCH_HAS_PMEM_API ENABLED\n");
+		}
+		else
+		{
+			dev_warn(dev, "CONFIG_ARCH_HAS_PMEM_API DISABLED!!!\n");
+		}
+		dev_warn(dev, "unable to guarantee persistence of writes fua=%d\n", fua);
 		fua = 0;
 	}
 
+	printk("%s: res=%pR", __FUNCTION__, res);
 	if (!devm_request_mem_region(dev, res->start, resource_size(res),
 				dev_name(&ndns->dev))) {
 		dev_warn(dev, "could not reserve region %pR\n", res);
@@ -427,7 +462,9 @@
 	pmem->pfn_flags = PFN_DEV;
 	if (is_nd_pfn(dev)) {
 		pmem->pgmap.type = MEMORY_DEVICE_FS_DAX;
+		dump_stack();
 		addr = devm_memremap_pages(dev, &pmem->pgmap);
+		printk("1 aaaddr=%p", addr);
 		pfn_sb = nd_pfn->pfn_sb;
 		pmem->data_offset = le64_to_cpu(pfn_sb->dataoff);
 		pmem->pfn_pad = resource_size(res) -
@@ -440,12 +477,16 @@
 		pmem->pgmap.range.end = res->end;
 		pmem->pgmap.nr_range = 1;
 		pmem->pgmap.type = MEMORY_DEVICE_FS_DAX;
+		dump_stack();
 		addr = devm_memremap_pages(dev, &pmem->pgmap);
+		printk("2 aaaddr=%p", addr);
 		pmem->pfn_flags |= PFN_MAP;
 		bb_range = pmem->pgmap.range;
 	} else {
 		addr = devm_memremap(dev, pmem->phys_addr,
 				pmem->size, ARCH_MEMREMAP_PMEM);
+		printk("3 aaaddr=%p pmem->phys_addr=%p pmem->size=0x%x", addr, pmem->phys_addr, pmem->size);
+		printk("res->start=%p res->end=%p", res->start, res->end);
 		bb_range.start =  res->start;
 		bb_range.end = res->end;
 	}
diff -ruN linux-5.18.orig/drivers/nvdimm/region_devs.c linux-5.18/drivers/nvdimm/region_devs.c
--- linux-5.18.orig/drivers/nvdimm/region_devs.c	2022-05-22 23:52:31.000000000 +0400
+++ linux-5.18/drivers/nvdimm/region_devs.c	2022-10-31 15:48:28.408495963 +0400
@@ -1003,6 +1003,8 @@
 		nd_region->mapping[i].nvdimm = nvdimm;
 		nd_region->mapping[i].start = mapping->start;
 		nd_region->mapping[i].size = mapping->size;
+		printk("nd_region->mapping[i].start=%p size=%llx", nd_region->mapping[i].start,
+			nd_region->mapping[i].size);
 		nd_region->mapping[i].position = mapping->position;
 		INIT_LIST_HEAD(&nd_region->mapping[i].labels);
 		mutex_init(&nd_region->mapping[i].lock);
@@ -1069,10 +1071,16 @@
 	int rc = 0;
 
 	if (!nd_region->flush)
+	{
 		rc = generic_nvdimm_flush(nd_region);
+		printk("nvdimm_flush1\n");
+	}
 	else {
 		if (nd_region->flush(nd_region, bio))
+		{
 			rc = -EIO;
+			printk("nvdimm_flush2\n");
+		}
 	}
 
 	return rc;
diff -ruN linux-5.18.orig/drivers/nvdimm/virtio_pmem.c linux-5.18/drivers/nvdimm/virtio_pmem.c
--- linux-5.18.orig/drivers/nvdimm/virtio_pmem.c	2022-05-22 23:52:31.000000000 +0400
+++ linux-5.18/drivers/nvdimm/virtio_pmem.c	2022-12-14 14:29:37.930652483 +0400
@@ -8,12 +8,16 @@
  */
 #include "virtio_pmem.h"
 #include "nd.h"
+#include <linux/major.h>
+#include <linux/ioport.h>
 
 static struct virtio_device_id id_table[] = {
 	{ VIRTIO_ID_PMEM, VIRTIO_DEV_ANY_ID },
 	{ 0 },
 };
 
+static struct virtio_pmem *vpmem = NULL;
+
  /* Initialize virt queue */
 static int init_vq(struct virtio_pmem *vpmem)
 {
@@ -29,12 +33,77 @@
 	return 0;
 };
 
+static int open_mem(struct inode *inode, struct file *filp)
+{
+	#if 0
+	int rc;
+
+	if (!capable(CAP_SYS_RAWIO))
+		return -EPERM;
+
+	rc = security_locked_down(LOCKDOWN_DEV_MEM);
+	if (rc)
+		return rc;
+
+	if (iminor(inode) != DEVMEM_MINOR)
+		return 0;
+	#endif
+
+	/*
+	 * Use a unified address space to have a single point to manage
+	 * revocations when drivers want to take over a /dev/mem mapped
+	 * range.
+	 */
+	// filp->f_mapping = iomem_get_mapping();
+	pr_info("%s", __FUNCTION__);
+	printk("vpmem->start=0x%llx vpmem->size=0x%llx", vpmem->start, vpmem->size);
+	return 0;
+}
+
+static int mmap_mem(struct file *file, struct vm_area_struct *vma)
+{
+	pr_info("JK: %s", __FUNCTION__);
+	printk("vpmem->start=0x%llx vpmem->size=0x%llx", vpmem->start, vpmem->size);
+
+	// vma->vm_page_prot = phys_mem_access_prot(file, vma->vm_pgoff,
+	// 					 vpmem->size,
+	// 					 vma->vm_page_prot);
+
+	int ret;
+	unsigned long pfn;
+	pfn = vpmem->start >> PAGE_SHIFT;
+	ret = io_remap_pfn_range(vma, vma->vm_start, pfn, vpmem->size, vma->vm_page_prot);
+	if (ret < 0) 
+	{
+		pr_err("could not map the address area\n");
+		return -EIO;
+	}
+
+	return 0;
+}
+
+static const struct file_operations __maybe_unused mem_fops = {
+#if 0
+	.llseek		= memory_lseek,
+	.read		= read_mem,
+	.write		= write_mem,
+#endif
+	.mmap		= mmap_mem,
+	.open		= open_mem,
+#if 0
+#ifndef CONFIG_MMU
+	.get_unmapped_area = get_unmapped_area_mem,
+	.mmap_capabilities = memory_mmap_capabilities,
+#endif
+#endif
+};
+
 static int virtio_pmem_probe(struct virtio_device *vdev)
 {
 	struct nd_region_desc ndr_desc = {};
 	int nid = dev_to_node(&vdev->dev);
 	struct nd_region *nd_region;
-	struct virtio_pmem *vpmem;
+//	struct virtio_pmem *vpmem;
 	struct resource res;
 	int err = 0;
 
@@ -49,7 +118,8 @@
 		err = -ENOMEM;
 		goto out_err;
 	}
-
+	printk("JK: -------------------------------");
+	dump_stack();
 	vpmem->vdev = vdev;
 	vdev->priv = vpmem;
 	err = init_vq(vpmem);
@@ -65,6 +135,8 @@
 
 	res.start = vpmem->start;
 	res.end   = vpmem->start + vpmem->size - 1;
+	printk("vpmem->start=0x%llx vpmem->size=0x%llx res.end=0x%llx", vpmem->start, vpmem->size, res.end);
+	#if 0
 	vpmem->nd_desc.provider_name = "virtio-pmem";
 	vpmem->nd_desc.module = THIS_MODULE;
 
@@ -90,6 +162,13 @@
 		goto out_nd;
 	}
 	nd_region->provider_data = dev_to_virtio(nd_region->dev.parent->parent);
+	#endif
+
+	/* TODO: jarekk: PHONE_MAJOR replace with other one*/
+	if (register_chrdev(PHONE_MAJOR, "sharedmem", &mem_fops))
+		printk("unable to get major %d for sharedmem devs\n", PHONE_MAJOR);
+
+
 	return 0;
 out_nd:
 	nvdimm_bus_unregister(vpmem->nvdimm_bus);
@@ -103,6 +182,7 @@
 {
 	struct nvdimm_bus *nvdimm_bus = dev_get_drvdata(&vdev->dev);
 
+	dump_stack();
 	nvdimm_bus_unregister(nvdimm_bus);
 	vdev->config->del_vqs(vdev);
 	virtio_reset_device(vdev);
diff -ruN linux-5.18.orig/drivers/pci/bus.c linux-5.18/drivers/pci/bus.c
--- linux-5.18.orig/drivers/pci/bus.c	2022-05-22 23:52:31.000000000 +0400
+++ linux-5.18/drivers/pci/bus.c	2022-12-12 14:02:49.318299262 +0400
@@ -198,6 +198,7 @@
 		max = avail.end;
 
 		/* Ok, try it out.. */
+		dump_stack();
 		ret = allocate_resource(r, res, size, min_used, max,
 					align, alignf, alignf_data);
 		if (ret == 0)
diff -ruN linux-5.18.orig/drivers/pci/pci.c linux-5.18/drivers/pci/pci.c
--- linux-5.18.orig/drivers/pci/pci.c	2022-05-22 23:52:31.000000000 +0400
+++ linux-5.18/drivers/pci/pci.c	2022-12-13 13:46:43.067947436 +0400
@@ -235,12 +235,16 @@
 
 void __iomem *pci_ioremap_bar(struct pci_dev *pdev, int bar)
 {
+	printk("Device=%04x", pdev->subsystem_device);
+	dump_stack();
 	return __pci_ioremap_resource(pdev, bar, false);
 }
 EXPORT_SYMBOL_GPL(pci_ioremap_bar);
 
 void __iomem *pci_ioremap_wc_bar(struct pci_dev *pdev, int bar)
 {
+	printk("Device=%04x", pdev->subsystem_device);
+	dump_stack();
 	return __pci_ioremap_resource(pdev, bar, true);
 }
 EXPORT_SYMBOL_GPL(pci_ioremap_wc_bar);
@@ -4327,7 +4331,8 @@
 		name = devm_kstrdup(dev, dev_name(dev), GFP_KERNEL);
 	if (!name)
 		return IOMEM_ERR_PTR(-ENOMEM);
-
+	dump_stack();
+	printk("devm_pci_remap_cfg_resource: ---- start=%p size=%x name=%s", res->start, size, name);
 	if (!devm_request_mem_region(dev, res->start, size, name)) {
 		dev_err(dev, "can't request region for resource %pR\n", res);
 		return IOMEM_ERR_PTR(-EBUSY);
diff -ruN linux-5.18.orig/drivers/virtio/virtio_pci_modern.c linux-5.18/drivers/virtio/virtio_pci_modern.c
--- linux-5.18.orig/drivers/virtio/virtio_pci_modern.c	2022-05-22 23:52:31.000000000 +0400
+++ linux-5.18/drivers/virtio/virtio_pci_modern.c	2022-12-12 16:18:29.872080195 +0400
@@ -363,7 +363,7 @@
 
 	if (!virtio_pci_find_shm_cap(pci_dev, id, &bar, &offset, &len))
 		return false;
-
+	dump_stack();
 	phys_addr = pci_resource_start(pci_dev, bar);
 	bar_len = pci_resource_len(pci_dev, bar);
 
diff -ruN linux-5.18.orig/drivers/virtio/virtio_pci_modern_dev.c linux-5.18/drivers/virtio/virtio_pci_modern_dev.c
--- linux-5.18.orig/drivers/virtio/virtio_pci_modern_dev.c	2022-05-22 23:52:31.000000000 +0400
+++ linux-5.18/drivers/virtio/virtio_pci_modern_dev.c	2022-12-12 16:18:53.280497126 +0400
@@ -90,6 +90,7 @@
 		return NULL;
 	}
 
+	dump_stack();
 	p = pci_iomap_range(dev, bar, offset, length);
 	if (!p)
 		dev_err(&dev->dev,
diff -ruN linux-5.18.orig/mm/memory.c linux-5.18/mm/memory.c
--- linux-5.18.orig/mm/memory.c	2022-05-22 23:52:31.000000000 +0400
+++ linux-5.18/mm/memory.c	2022-12-14 15:15:45.166218472 +0400
@@ -622,7 +622,7 @@
 			return NULL;
 		if (pte_devmap(pte))
 			return NULL;
-
+		printk("------------------- CONFIG_ARCH_HAS_PTE_SPECIAL");
 		print_bad_pte(vma, addr, pte, NULL);
 		return NULL;
 	}
@@ -649,6 +649,7 @@
 
 check_pfn:
 	if (unlikely(pfn > highest_memmap_pfn)) {
+		printk("--------------- check_pfn");
 		print_bad_pte(vma, addr, pte, NULL);
 		return NULL;
 	}
@@ -1388,7 +1389,11 @@
 			rss[mm_counter(page)]--;
 			page_remove_rmap(page, vma, false);
 			if (unlikely(page_mapcount(page) < 0))
+			{
 				print_bad_pte(vma, addr, ptent, page);
+				printk("----------> page_mapcount");
+			}
+			
 			if (unlikely(__tlb_remove_page(tlb, page))) {
 				force_flush = 1;
 				addr += PAGE_SIZE;
@@ -1413,7 +1418,10 @@
 				continue;
 			rss[MM_SWAPENTS]--;
 			if (unlikely(!free_swap_and_cache(entry)))
+			{
 				print_bad_pte(vma, addr, ptent, NULL);
+				printk("----------> free_swap_and_cache");
+			}
 		} else if (is_migration_entry(entry)) {
 			page = pfn_swap_entry_to_page(entry);
 			if (!should_zap_page(details, page))
diff -ruN linux-5.18.orig/mm/memory_hotplug.c linux-5.18/mm/memory_hotplug.c
--- linux-5.18.orig/mm/memory_hotplug.c	2022-05-22 23:52:31.000000000 +0400
+++ linux-5.18/mm/memory_hotplug.c	2022-12-12 13:36:46.519451191 +0400
@@ -1466,6 +1466,7 @@
 int add_memory_driver_managed(int nid, u64 start, u64 size,
 			      const char *resource_name, mhp_t mhp_flags)
 {
+	dump_stack();
 	struct resource *res;
 	int rc;
 
diff -ruN linux-5.18.orig/mm/memremap.c linux-5.18/mm/memremap.c
--- linux-5.18.orig/mm/memremap.c	2022-05-22 23:52:31.000000000 +0400
+++ linux-5.18/mm/memremap.c	2022-12-13 12:26:29.121286918 +0400
@@ -292,6 +292,7 @@
 	const int nr_range = pgmap->nr_range;
 	int error, i;
 
+	dump_stack();
 	if (WARN_ONCE(!nr_range, "nr_range must be specified\n"))
 		return ERR_PTR(-EINVAL);
 
@@ -387,6 +388,7 @@
 	int error;
 	void *ret;
 
+	dump_stack();
 	ret = memremap_pages(pgmap, dev_to_node(dev));
 	if (IS_ERR(ret))
 		return ret;
diff -ruN linux-5.18.orig/kernel/iomem.c linux-5.18/kernel/iomem.c
--- linux-5.18.orig/kernel/iomem.c	2022-05-22 23:52:31.000000000 +0400
+++ linux-5.18/kernel/iomem.c	2022-12-14 11:37:24.467420753 +0400
@@ -141,6 +141,8 @@
 {
 	void **ptr, *addr;
 
+	dump_stack();
+	printk("%s: Size=0x%x", __FUNCTION__, size);
 	ptr = devres_alloc_node(devm_memremap_release, sizeof(*ptr), GFP_KERNEL,
 			dev_to_node(dev));
 	if (!ptr)
@@ -155,6 +157,7 @@
 		return ERR_PTR(-ENXIO);
 	}
 
+	printk("%s: addr=%pR", __FUNCTION__, addr);
 	return addr;
 }
 EXPORT_SYMBOL(devm_memremap);
diff -ruN linux-5.18.orig/kernel/resource.c linux-5.18/kernel/resource.c
--- linux-5.18.orig/kernel/resource.c	2022-05-22 23:52:31.000000000 +0400
+++ linux-5.18/kernel/resource.c	2022-12-14 11:01:58.144271309 +0400
@@ -283,6 +283,7 @@
 {
 	struct resource *conflict;
 
+	// dump_stack();
 	conflict = request_resource_conflict(root, new);
 	return conflict ? -EBUSY : 0;
 }
@@ -1567,6 +1568,9 @@
 	struct region_devres *dr = NULL;
 	struct resource *res;
 
+	// dump_stack();
+	// printk("__devm_request_region: ---- start=%pR n=%x name=%pR", start, n, name);
+
 	dr = devres_alloc(devm_region_release, sizeof(struct region_devres),
 			  GFP_KERNEL);
 	if (!dr)
@@ -1577,6 +1581,7 @@
 	dr->n = n;
 
 	res = __request_region(parent, start, n, name, 0);
+	// printk("__devm_request_region: ---- res=%pR", res);
 	if (res)
 		devres_add(dev, dr);
 	else
